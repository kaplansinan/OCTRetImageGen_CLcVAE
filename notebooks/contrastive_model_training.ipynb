{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob \n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " assert tf.__version__ == '2.4.1' , \"TF version is not matching! Make sure you have tf 2.4.1-gpu installed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enable GPU memory growth - avoid allocating all memory at start\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(device=gpu, enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import custom functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.dataloader.contrastive_learning_loader import debug_batch_of_data, get_training_tfdata,get_test_or_validation_tfdata,view_batch_of_images\n",
    "from src.models import get_model_func\n",
    "from src.utils.tf_utils import get_preprocess_func\n",
    "from src.train_config import config\n",
    "from src.utils.custom_losses import SupervisedContrastiveLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model and print summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL ###\n",
    "model_func = get_model_func(config)\n",
    "model = model_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define keras callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keras_callbacks(log_dir:str):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10) #loss - training, val_loss - validationset loss\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger(os.path.join(log_dir,'training.log'))\n",
    "    model_ckp = tf.keras.callbacks.ModelCheckpoint(\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        # The saved model name will include the current epoch.\n",
    "        filepath=os.path.join(log_dir,\"model_{epoch}.h5\"),\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        save_weights_only=True,\n",
    "        monitor=\"loss\", # training onlu\n",
    "    )\n",
    "    term_nan = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,  # How often to log histogram visualizations\n",
    "        embeddings_freq=0,  # How often to log embedding visualizations\n",
    "        update_freq=\"epoch\",\n",
    "        profile_batch = 2\n",
    "    )  # How often to write logs (default: once per epoch)\n",
    "    return [early_stop,csv_logger,model_ckp,tensorboard,term_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOGDIR to save results\n",
    "log_dir = os.path.join('/model_registry/output',datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hyperparameters and optimizer for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.5\n",
    "temperature = 0.05\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    learning_rate, decay_steps=100000, decay_rate=0.95, staircase=True\n",
    ")\n",
    "\n",
    "m_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "## Compile model\n",
    "model.compile(\n",
    "    optimizer=m_optimizer,\n",
    "    #custom loss function\n",
    "    loss=SupervisedContrastiveLoss(temperature),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training set as tf.data instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "train_csv_path =  \"/data/oct_train_filtered.csv\" \n",
    "print(train_csv_path)\n",
    "# read csv file \n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the set as tf.data\n",
    "tf_train_set = get_training_tfdata(train_df,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize batch of images\n",
    "view_batch_of_images(tf_train_set,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_batch_of_data(tf_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get callbacks and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_list =  get_keras_callbacks(log_dir)\n",
    "history = model.fit(tf_train_set,\n",
    "                epochs=num_epochs,\n",
    "                callbacks=cb_list,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract embeddings for each sample in training set and save them under data folder\n",
    "The embedding of each sample from the trained contrastive model will be used for training Conditional Variational Autoencoder mode. Hence, it is important to execute this step after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model (change model name as needed)\n",
    "model.load_weights(\"model_registry/output/20220422-160825/model_50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train csv\n",
    "train_csv_path =  \"/data/oct_train_filtered.csv\" \n",
    "print(train_csv_path)\n",
    "# read csv file \n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITY FUNCTIONS\n",
    "from src.dataloader.contrastive_learning_loader import _denorm\n",
    "\n",
    "preprocessing_func=get_preprocess_func(config)\n",
    "def open_gray(fn):\n",
    "    img = cv2.cvtColor(cv2.imread(fn), cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    return img\n",
    "\n",
    "def read_image_3_channel(path):\n",
    "    img = open_gray(path)\n",
    "    img = cv2.resize(img, (256, 256), cv2.INTER_LINEAR)\n",
    "#     img = img/255.\n",
    "     # Apply model-specific preprocessing function\n",
    "    img = preprocessing_func(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding save pat \n",
    "emb_save_path = \"/data/processed/contrastive_learning/train_embeddings/\" \n",
    "os.makedirs(emb_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract embedding for each sample and save\n",
    "encoder_emb_list = []\n",
    "for indx,row in tqdm(train_df.iterrows()):\n",
    "    pre_procc_img_2 = read_image_3_channel(row['path'])\n",
    "    pre_procc_img_2 = np.expand_dims(pre_procc_img_2,axis=0)\n",
    "    pred_emb = model.predict(pre_procc_img_2)\n",
    "    pred_emb = np.asarray(pred_emb).ravel()\n",
    "    # basename \n",
    "    basename = os.path.basename(row['path'])\n",
    "    tmp_emb_save = os.path.join(emb_save_path,basename)\n",
    "    np.save(tmp_emb_save, pred_emb)\n",
    "    # run inference and quantize embedding precision\n",
    "    encoder_emb_list.append(pred_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save embeddings and train ids as a complete numpy array\n",
    "save_folder = \"/data/processed/contrastive_learning/\"\n",
    "embeddings = np.concatenate(encoder_emb_list, axis=0)\n",
    "np.save(os.path.join(save_folder, 'train_embeddings.npy'), embeddings)\n",
    "# save filenames\n",
    "fn_arr = np.array(list(train_df.path.values))\n",
    "print(fn_arr.shape)\n",
    "np.save(os.path.join(save_folder, 'train_ids.npy'), fn_arr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c712e6ad3bb19fb96005b675848074763a7b92d35ac6a564d68368545f5a2b8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
